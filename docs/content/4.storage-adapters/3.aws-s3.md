---
title: AWS S3
description: Upload files to Amazon S3 and S3-compatible services using presigned URLs.
navigation:
  icon: i-simple-icons-amazons3
---

# AWS S3

::prose-callout{type="warning" title="Experimental"}
This adapter is experimental and may change in future releases.
::

The `PluginAWSS3` adapter uploads files to Amazon S3 using presigned URLs. This approach keeps your AWS credentials secure on the server while allowing direct client-to-S3 uploads.

::prose-tip
This adapter also works with S3-compatible services like **MinIO**, **DigitalOcean Spaces**, **Wasabi**, and **Backblaze B2**.
::

## Installation

No client-side dependencies required! The adapter uses native `fetch` and `XMLHttpRequest` for uploads.

Your **backend** will need the AWS SDK to generate presigned URLs:

```bash [Terminal]
pnpm add @aws-sdk/client-s3 @aws-sdk/s3-request-presigner
```

## Usage

```ts
import { PluginAWSS3 } from "nuxt-upload-kit/providers/aws-s3"

const uploader = useUploadKit({
  storage: PluginAWSS3({
    getPresignedUploadUrl: async (fileId, contentType, { fileName, fileSize }) => {
      const response = await fetch("/api/s3/presign", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ key: fileId, contentType, fileName, fileSize }),
      })
      return response.json()
    },
  }),
})
```

## Options

| Option                   | Type                                                    | Required | Description                              |
| ------------------------ | ------------------------------------------------------- | -------- | ---------------------------------------- |
| `getPresignedUploadUrl`  | `(fileId, contentType, metadata) => Promise<{...}>`     | Yes      | Function to fetch presigned upload URL   |
| `getPresignedDownloadUrl`| `(fileId) => Promise<string>`                           | No       | Function to fetch presigned download URL |
| `deleteFile`             | `(fileId) => Promise<void>`                             | No       | Function to delete a file via your API   |
| `retries`                | `number`                                                | No       | Number of retry attempts (default: 3)    |
| `retryDelay`             | `number`                                                | No       | Initial retry delay in ms (default: 1000)|

## Backend Setup

### Generate Presigned Upload URL

Create an API endpoint to generate presigned URLs:

```ts [server/api/s3/presign.post.ts]
import { S3Client, PutObjectCommand } from "@aws-sdk/client-s3"
import { getSignedUrl } from "@aws-sdk/s3-request-presigner"

const s3 = new S3Client({
  region: process.env.AWS_REGION!,
  credentials: {
    accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!,
  },
})

const BUCKET = process.env.AWS_S3_BUCKET!

export default defineEventHandler(async (event) => {
  const { key, contentType, fileName, fileSize } = await readBody(event)

  // Optional: Add validation, path prefixing, etc.
  const objectKey = `uploads/${key}`

  const command = new PutObjectCommand({
    Bucket: BUCKET,
    Key: objectKey,
    ContentType: contentType,
    Metadata: {
      "original-name": fileName,
      "file-size": String(fileSize),
    },
  })

  const uploadUrl = await getSignedUrl(s3, command, { expiresIn: 3600 })

  return {
    uploadUrl,
    publicUrl: `https://${BUCKET}.s3.${process.env.AWS_REGION}.amazonaws.com/${objectKey}`,
  }
})
```

### Generate Presigned Download URL (Optional)

For private buckets, create an endpoint to generate download URLs:

```ts [server/api/s3/download/[key].get.ts]
import { S3Client, GetObjectCommand } from "@aws-sdk/client-s3"
import { getSignedUrl } from "@aws-sdk/s3-request-presigner"

const s3 = new S3Client({ /* ... */ })

export default defineEventHandler(async (event) => {
  const key = getRouterParam(event, "key")

  const command = new GetObjectCommand({
    Bucket: process.env.AWS_S3_BUCKET!,
    Key: `uploads/${key}`,
  })

  return await getSignedUrl(s3, command, { expiresIn: 3600 })
})
```

### Delete File (Optional)

```ts [server/api/s3/delete/[key].delete.ts]
import { S3Client, DeleteObjectCommand } from "@aws-sdk/client-s3"

const s3 = new S3Client({ /* ... */ })

export default defineEventHandler(async (event) => {
  const key = getRouterParam(event, "key")

  await s3.send(new DeleteObjectCommand({
    Bucket: process.env.AWS_S3_BUCKET!,
    Key: `uploads/${key}`,
  }))

  return { success: true }
})
```

## Complete Example

```ts
import { PluginAWSS3 } from "nuxt-upload-kit/providers/aws-s3"

const uploader = useUploadKit({
  storage: PluginAWSS3({
    getPresignedUploadUrl: async (fileId, contentType, metadata) => {
      const response = await fetch("/api/s3/presign", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ key: fileId, contentType, ...metadata }),
      })
      if (!response.ok) throw new Error("Failed to get upload URL")
      return response.json()
    },

    getPresignedDownloadUrl: async (fileId) => {
      const response = await fetch(`/api/s3/download/${fileId}`)
      return response.text()
    },

    deleteFile: async (fileId) => {
      await fetch(`/api/s3/delete/${fileId}`, { method: "DELETE" })
    },

    retries: 3,
    retryDelay: 1000,
  }),
})
```

## Upload Result

After successful upload, `file.uploadResult` contains:

```ts
{
  url: 'https://my-bucket.s3.us-east-1.amazonaws.com/uploads/abc123.jpg',
  key: 'abc123.jpg',
  etag: 'd41d8cd98f00b204e9800998ecf8427e'  // Optional, from S3 response
}
```

## S3-Compatible Services

### DigitalOcean Spaces

```ts [server/api/spaces/presign.post.ts]
const s3 = new S3Client({
  region: "nyc3",
  endpoint: "https://nyc3.digitaloceanspaces.com",
  credentials: {
    accessKeyId: process.env.DO_SPACES_KEY!,
    secretAccessKey: process.env.DO_SPACES_SECRET!,
  },
})
```

### MinIO

```ts [server/api/minio/presign.post.ts]
const s3 = new S3Client({
  region: "us-east-1",
  endpoint: "http://localhost:9000",
  forcePathStyle: true, // Required for MinIO
  credentials: {
    accessKeyId: process.env.MINIO_ACCESS_KEY!,
    secretAccessKey: process.env.MINIO_SECRET_KEY!,
  },
})
```

### Backblaze B2

```ts [server/api/b2/presign.post.ts]
const s3 = new S3Client({
  region: "us-west-002",
  endpoint: "https://s3.us-west-002.backblazeb2.com",
  credentials: {
    accessKeyId: process.env.B2_KEY_ID!,
    secretAccessKey: process.env.B2_APP_KEY!,
  },
})
```

## CORS Configuration

Ensure your S3 bucket allows uploads from your domain:

```json [CORS Configuration]
[
  {
    "AllowedHeaders": ["*"],
    "AllowedMethods": ["PUT", "HEAD"],
    "AllowedOrigins": ["https://your-domain.com"],
    "ExposeHeaders": ["ETag"],
    "MaxAgeSeconds": 3600
  }
]
```

Apply via AWS CLI:

```bash
aws s3api put-bucket-cors --bucket my-bucket --cors-configuration file://cors.json
```

## Error Handling

The adapter includes built-in retry logic with exponential backoff:

```ts
PluginAWSS3({
  getPresignedUploadUrl: /* ... */,
  retries: 5,      // Try up to 5 times
  retryDelay: 2000 // Start with 2s delay, doubles each retry
})
```

Retry sequence: 2s → 4s → 8s → 16s → fail

## Troubleshooting

### "403 Forbidden" on Upload

1. Check your presigned URL hasn't expired
2. Verify the `Content-Type` header matches what was signed
3. Ensure CORS is configured correctly

### "SignatureDoesNotMatch"

The request doesn't match what was signed. Common causes:

- Content-Type mismatch between presign and upload
- Extra headers being sent that weren't included in signing

### No Progress Updates

Ensure you're not using a proxy that buffers the request. The progress is tracked via `XMLHttpRequest.upload.onprogress`.
